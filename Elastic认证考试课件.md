# 考试介绍

## 1 Elastic认证介绍

Elastic认证，即：Elastic Certified Engineer（Elastic认证工程师），官方的解释是Elastic官方推出的对于Elasticsearch技术的专家认证。国内多位一线大厂高级架构师、CTO都表示对此认证十分认可。
认证者需要通过Elastic官方的认证专家考试，费用为400美元。用一句话来概括，就是用400美元证明你很屌（前提是通过考试）。

**认证证书**：

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/395d4c4982ff4a14bb42fe1f186e9fa9.png)

**通过考试将收到官方从米国寄来的铜制几年徽章：**

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/1c1348731c794ecdb03b771a219c21f0.png)

## 2 认证证书含金量

截止到2021年2月，中国的Elastic认证工程师有一百零几人。

截止到2021年7月9日，国内通过认证考试人数也不到200人。官方给我的确认邮件是超过一百人，所以这的200人是保守的估计，实际情况大概不到一百五十人。难，才证明有价值，如果是花钱就能过，那认证等同于一张废纸。

截止到2022年3月20日，国内预估通过考试人数200+，其中80+人出自 `Elastic开源社区` ，Elastic开源社区仅用半年时间就培养了超过80位认证工程师。

**证书含金量**：非常高。这是Elastic官方颁发的认证证书，是你成为搜索技术专家最权威的证明。而且，从经济学的角度上分析，物以稀为贵。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/8063086d6d2e4b2f8938cda33a0e8e49.png)

## 3 考试形式

### 3.1 考试时间

考试时间在一年的365天中任意一天都可以，只要你觉得你达到了考试的要求，你随时可以预约考试。但是前提是你要在考试24小时以前预约考试。

### 3.2 考场要求

场地要求是一个密闭的房间，可以是卧室或者是你的办公室，会议室都可以。官方只说明房间尽可能的干净整洁，没有给出房间的具体要求，我给大家的建议是尽可能的把房间内和考试不相关的东西都收起来。放在柜子里或者房间外面让监考官看不见就可以，考场上允许使用的东西是首先一张桌子，一张椅子。你考试的电脑显示器，鼠标，键盘和一杯水。不允许带智能手机，智能手表，耳机等其他可能被监考官判定用于作弊的任何物品。如果你的房间里衣服非常多，建议收纳起来。官方并没有说多干净的房间可以达到要求，我给大家的建议是最好房间里光秃秃，什么也没有。因为你的房间越干净，在考试的时候就可以尽可能的少和监考官在是房间的问题上做出不必要的沟通，从而浪费时间。举个例子，比如说监考官让你把桌子上的PS5拿走，他有可能说的是英文，但是说了半天，你也不懂他在说什么，就有可能耽误很多时间，虽然和监考官沟通的时间不计入考试时间，但是会影响你的心态，而且有的监考官有些不讲道理。如果你和他沟通的时间过长，他会阻止你考试。这样的情况时有发生。

下面给出一个考试房间的参考标准

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/d62792a724be44068bd86f7059515012.png)

### 3.3 电脑要求

无特殊要求，Windows、MacOS、M1电脑都可以，不支持用Linux系统参加考试。

### 3.4 考试证件

考试允许使用的证件，包括护照，港澳通行证或者身份证。需要注意的是，如果你要使用身份证参加考试，需要提前和官方发邮件提出申请，得到官方明确允许使用身份证参加考试的邮件。这里可能会存在一些风险，如果大家有条件办理护照或者港澳通行证，我建议大家还是使用护照或者港澳通行证参加考试是百分之百没问题的。

疫情原因护照办理上可能困难比较大，我推荐。大家办理港澳通行证参加考试。

* **护照**
* **港澳通行证**
* **身份证**

各地方办理护照或港澳通行证的政策有所不同。北京已不受理外地户籍办理护照。需要和户口所在地出入境办事处沟通询问具体办理护照的相关事项。护照或港澳通行证的办理需要一定的时间周期，建议近期有准备考试打算的同学提前沟通，提前办理证件。课件中包含了可能会用到的一些办理证件的材料。包括护照的申请书以及证明办理护照仅用于考试的文件。

**办理护照可能需要的材料：**

https://t.zsxq.com/yVFaEYn（资源和数据下载课件中也有体现：http://cloud.fynote.com/edit?nid=34458&id=1647953007097），两个链接哪个能下载用哪个，如果提示付费不要管它。

### 3.5 是否开卷

是的时候是允许访问官方文档的，但是大家都知道。即便是开卷考试，并不代表考试就特别简单。首先官方文档内容非常多。考试时间有限，你要在有限的时间内找到快速定位文档你首先就要对文档特别熟悉。其次官方文档是考试期间唯一可以查看的资料。考试期间不允许使用百度或者谷歌等搜索引擎搜索答案。

## 4、考试题型及难度

考试题型一共有两大类。一类是代码题。主要包含dsl。和查询。脚本查询等等主要通过代码来完成。二类是集群实战体，给出若干个服务器要求你在服务器上按照指定的要求配置节点。形成集群并达到题目要求。比如跨级群搜索，跨级群复制。集群安全等等。考试内容不包含选择题，填空题，问答题和判断题。考试没有可以蒙的可能性，所以是有一定难度的。

### 4.1 代码题

Query DSL、Aggregations和Scripting的实战题目，考察各种应用场景下的脚本功底。如下图：

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/785b2703d7be4106bc25213822fccdad.png)

写出符合题目要求的DSL语句，包括聚合查询和脚本查询。一般要求有3-4个。考察多个知识点，考试的时候注意审题，有的题目要求包含请求头，要的要求不包含。

### 4.2 集群实战题

集群架构部署题目，需要在真实环境部署完全符合要求的集群并且能正常运行。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/78fe8318223849d2a4c3f475858a2b4d.png)

## 5、证书有效期问题

首先，证书的有效期是从考试通过那一天开始算，两年时间。有人对这个时间限制非常在意，大家请注意。国外的考试证书几乎都有时间限制，大家不用对这个时间特别在意。除非有些国企或事业单位需要挂靠，其他情况即便证书过期之后，你仍然是认证工程师，你在面试的时候或者简历里边儿都可以说自己是认证工程师，这完全是没有问题的，因为你考试通过之后，不仅仅收获的是证书本身，更多的是对考试包含的知识点的技能掌握。换句话说就是实力的提升，这是不可否认的。国外的考试非常注重解决实战问题，当你能通过考试的时候，实际上你已经具备了非常强的解决生产实战问题的能力。

如果对证书的时间限制确实非常在意。我们后期也有很多手段延长证书的有效期。认证考试共有三种。三种证书分别适合开发者，数据分析师和运维工程师。我们考试的这个叫ECE，是比较适合编程语言开发者或者架构师的。比如你是Java程序员，Python或者php程序员都可以。当我们的证书有效期快到的时候，我们可以通过考试另外两个证书。给当前这个证书续期。也就是说当ECE证书快到期的时候，你考ECA证书。不仅收获了ECA证书，还可以给ECE证书续期两年。

# 备考必看

## 1 特训大纲

### 1.1 课程部分（直播/录播）

**课程内容**

我们的elastic认证考试特训班分为四个阶段。课程部分仅是我们培训的第一个阶段。不管是直播还是录播，我们视频内容囊括了和考试相关的所有内容。包括考试需要准备的物料、学习方法以及知识点讲解。关于第一阶段的学习，大家普遍存在一些误区：尤其是对于零基础的同学而言，千万不要在视频上面死磕。认证考试本身是基于有经验的同学的课程。所以课程一般来说讲的比较快，尤其是直播。因为我们追求的是效率。我们要在最短的时间内拿到认证考试证书。学习压力会迫使你提高自己的效率。也是督促式学习的一个宗旨。

**看课达标标准**

课程学习阶段的达标标准是能做出课后所布置的习题即可。当然做题的时候标准是指参考官方文档而不查阅其他任何资料。有可能在第一遍做题的时候，你仍然需要查阅课件。但是查阅课件把题目做出来并不算符合要求，而要靠自己。除了官方文档，不查阅任何资料是必要条件。只要达到了这个要求，视频就继续往后看了，或者往后跟直播了。视频学习阶段切记不要反复的看，这样会浪费时间。一定要有针对性的去看。比如说我在做题的时候发现某个知识点不太清楚，首先应尝试在备考群里咨询同学或者老师，有的问题对自己而言可能是非常困难的，但对之前考过试或者学习过这个知识点的同学来说就非常简单。所以在群里提问基本上能得到非常快的答复。如果遇到了困难的问题解决不了，可在群里艾特老师。

**看课误区**

看视频最大的误区就是想通过视频对考试的所有考点掌握得特别透彻。所以很多人就会陷入重复看视频的误区。这样是比较浪费时间的。视频或者直播只要达到上述的要求，即便没有特别精通也没有关系。因为我们后面还有查漏补缺及强化训练，通过做题等手段来加强对知识点的掌握。所以只要按照老师的要求来，效率一定是最高的。老师说跳过的东西一定要跳过。

**把握好进阶学习时机，追求更高的效率**

视频或者直播看完之后一定要及时联络老师，规划后面的学习。整个备考阶段，直至拿到考试证书。都要和老师尽可能的多沟通，有任何学习上的问题或者障碍。或者觉得学习效率有问题，都可以和老师沟通。

### 1.2 查漏补缺

视频看完之后，其实短时间内还很难对所有知识点面面俱到。即使你有多年经验，在整个考试范围之内，也必定有你的知识盲区，我们就要通过做题的方式查漏补缺。我们课程附带资料里包含了非常全面的Elastic认证考试的题库。题库是结合了很多资源。包括，官方公布的资源，网上罗列的所有资源以及前考过同学的复盘总结等等。对包含了模拟题、题型讲解、考试真题、易错题分析还有学员自拟题等等可谓非常全面。

题库的题目是需要循序渐进的。需要有顺序有规律的去做，不然的话，只会耽误自身时间。武功的修炼也是由内而外，由浅入深的。如果没有扎实的基础，强行修炼武功秘籍只会心脉逆行，走火入魔。所以当视频看完之后，及时和老师沟通。以便安排学习路线。

### 1.3 强化训练

**遇见新题型**

知识库的真题是完全涵盖了目前已经考试过所有同学的模拟题及真题的。虽然说题目非常非常全面了，并不代表题目已经涵盖了所有的考点。因为到目前为止有的考点还没有出现过对应的题型。甚至已经考过的知识点也有可能会出现新的题型或者题目变动。这都不算超出考试范围之外。大部分人没有es多年的使用经验。在面对陌生题型的时候可能就手足无措了。这种情况是小概率事件，但不代表不可能会出现。针对这种情况，我们就需要做一些强化训练。以保证在面对突发情况或者陌生题型的时候，不至于束手无策。

**球友自拟题**

在我们的题库中包含了球友自拟题目。球友自拟题目是按照不能和目前已有题型重复这个前提要求。按照官方公布的考试大纲参考官方文档。球友自己出的题目，。其中就包含了一些比较生僻的题目，但是仍然是在考试范围之内的。这些题目会强化自己对一些陌生题行的应对能力，而且在做题的时候无形中又加强了对官方文档的记忆，可谓一举多得。但是遇见陌生题目，对目前而言，是小概率事件，也就是说做球友自拟题是收益比是比较低的一件事。换句话说，相当于长跑比赛的最后两百米。也许是最难的。

**真题训练**

强化训练最后一部分要求我们必须把考试真题全部做两遍以上。保证每一套题目在一个小时之内可以完成。这是硬性要求，每个人都必须做到。其主要目的是为了让大家了解考试的真题长什么样子。考试时间有三个小时，之所以要求大家必须一个小时之内完成，是因为你要有足够的时间应对突发情况。而一个小时这个时间节点是综合了上百位考生的综合考试情况做出的权衡值，已经反复验证，是最佳选择。再要求提速其实就很难了，意义也不大了，提升也很有限。有两个小时应对突发情况是很有必要，时间也是足够的。

### 1.4 考前指导

**考前避坑**

经过系统化的学习，每个人对知识点的掌握都可以做到足够应对考试。但是考试有一个非常大的问题，就是很多考生考试失败并非是失败在对知识点的掌握本身。而是一些其他的突发情况，比如说翻译。软件的问题。比如说网络的问题等等。诸如此类的和考试考点本身无关的突发情况非常非常多。甚至这些情况对你考试的影响超过了考点本身。

**复盘经验**

针对诸如此类问题，我们的应对手段是通过认真查阅之前所有考试学员的复盘总结的经验贴。还有老师的避坑指南。老师会在避坑指南中把所有可能会遇到的问题详细的罗列一遍，包括遇到这些问题如何去处理。通过刷复盘贴和查阅避坑指南，基本上就知道所有可能会出现的坑以及解决办法了。目前为止这种方法是非常有效果的。一个很不起眼的小问题可能直接就影响你考试成绩，甚至直接导致你考试失败了。所以考试复盘贴一定要看。

**考前联系老师**

另外，考试之前一定要联络老师做考前指导。目的是让老师帮助你，判断你是否具备了参加考试的条件。避免一些同学对自身实力掌握水平不够了解。参加考试而导致考试失败。可以最大程度的。增加我们一次通过考试的概率，降低我们的考试成本。

## 2 学前必看

### 2.1 官方考试大纲

**考纲：**[https://www.elastic.co/cn/training/elastic-certified-engineer-exam](https://www.elastic.co/cn/training/elastic-certified-engineer-exam)

### 2.2 官方FAQ

#### 2.2.1 官方地址

[https://www.elastic.co/cn/training/certification/faq](https://www.elastic.co/cn/training/certification/faq)

#### 2.3.2 重要信息提取

* 考试版本：7.13
* 考试费用：400美元
* 报名有效期：一年
* 可否补考：否
* 认证有效期：2年
* 在哪里考试：封闭的房间内
* 什么时候考试：你认为你能通过考试的时候

### 2.3 考试视频介绍

#### 2.3.1 旧版本介绍

**油管链接：**[https://www.youtube.com/watch?v=hsaLZSKCkF0](https://www.youtube.com/watch?v=hsaLZSKCkF0)（需科学上网）

#### 2.3.2 新版本介绍

**油管链接：**[https://www.youtube.com/watch?v=9UpB-s_ZfNE](https://www.youtube.com/watch?v=9UpB-s_ZfNE)（需科学上网）

**B站链接：** [https://www.bilibili.com/video/BV1EF411x7gQ?zw](https://www.bilibili.com/video/BV1EF411x7gQ?zw)（中文字幕）

# 学习方法论

## 1 建立信心

**必过考试的信念**

然你报名了咱们认证考试的课程，那么你已经没有选择的余地了，你必须选择相信自己能够通过考试。可以负责任的告诉你只要你愿意学，按照老师说的做，百分之百可以通过考试。咱们目前百分之百的通过率就足以说明问题。

其实这一点我不用解释太多。你就记住一句话，考试你一定能过。就可以了。

**对于老师的信心**

你看到这条视频的时候，老师这里已经有500号学生了。参加考试的也有近百人，剩下的一部分人有的正在筹备考试，有的由于个人情况，加班或者家庭原因要过一段时间。但是到目前为止，所有参加考试的人除了在等成绩的之外，得到考试结果的人都已经通过了考试。这说明老师规划的学习方案是100%没有问题的，并且效率也非常高。每一位学员也都付出了自己的努力。相信自己，相信老师！

**万事开头难**

老师除了讲课之外，其实很多时候也兼顾精神鼓励师的角色。因为咱们学员里大部分都是零基础入学的。基础想要试认试认证老师也不能不管，也不能不交。因为这是老师的责任。花了钱报了课，我就有义务让你通过考试。当然对于咱们基础基础想要通过考试还是需要下一定的功夫的。也有很多人中途想放弃的，觉得自己学不会。告诉你，这是所有人一开始都会面临的问题。

你要记住一句话：越是有困难，有挑战性的事情。一旦你做成功了就，那就是在你和别人制造壁垒，就是在提高你个人的核心竞争力和不可替代性。人的提升和进步就是尝试和努力。做自己没做过的事。做重复的工作或者自己已经会了的工作，那就是在浪费时间。所以不会没关系，慢慢儿来。痛苦不要紧。他是有价值的。听一首歌。休息一会儿，放松放松。合理的安排工作，学习和休息。

## 2 计划考试时间

**目标的重要性**

不管你相不相信。做成一件事一定要在事先制定一个合理的目标。然后就是朝着这个目标努力的去做。在这个过程中要坚持。不能半途而废。成功的原因有千万个。败的理败的理由只有一个，就是放弃。

**压力转为动力**

目标制定以后就不要朝令夕改。决定好的事儿就一定要做。当然如果真的有突发情况，那另当别论。目标存在的意义，另一方面也是给自己制造一定的压力。比如当时我计划6月29号考试。因为7月1号考纲就变了，可能自己又要浪费很多时间。所以我就狠下心来，一定要在6月29号之前考试。当时的工作是比咱们绝大多数人都要忙的，甚至经常要忙到凌晨三四点。但是我仍然没有放弃。当然我不是说咱们备考就要忙到这种程度。没有这么可怕的。因为我给了自己压力，所以在一些平常可能会浪费掉的时间，我就强迫自己用于备考。我备考比咱们所有人都要辛苦，第一个是因为时间少。第二个是因为我不像咱们现在已经有了这么多学习资料，还有老师带着。我不知道我学习到一个什么度度才能参加考试。因为没有人能告诉我。所以我其实是走了很多弯路的。

**方便老师跟进**

制定自己的考试目标之后向老师报备一下。这也方便老师跟进你的学习进度。我知道你还有多长时间考试你沟通你沟通。就是因为咱们学员众多。工作也难免有疏忽的地方。所以大家要要多和老师主动沟通。

## 3 最小化学习

**不要问为什么**

大部分同学都会陷入一个误区，就是当学习一个知识点的时候，往往会好奇为什么。也就是好奇他的理论原理。我在这里要郑重的强调一下。咱们参加认证考试目的性非常强。就是为了拿到认证证书。我们要以最短的时间内，以最高的效率通过考试。所以原则上来说和考试无关的内容，我们暂时都先跳过或者搁置。考试是不考任何原理性的东西的。所以如果你对某个知识点好奇它的原理是什么？我的建议是暂时先跳过，等到你通过考试之后。再回过头来学习。我并不是要告诉你理论学习没有必要，而是说就目前情况而言，我们要分主次。要分轻重缓急。一切以考试优先。

**让跳过的内容一定要跳过**

最小化学习路线就是为每个人量身定制。个性化学习路线，每个人的情况不同，所需要掌握的前置知识也不同。按照老师规划的四步学习大纲学习肯定是没有问题的。你也可以根据自身情况做出一些调整。但是切忌本末导致，眼高手低。

老师所总结的学习方法。是结合了上百位考生的经验总结而来。就是最佳学习路线。一定要对自己和老师建立信心。跟我们通过率100%，足以说明一切。

## 4 时间和效率管理

**不要给自己找借口**

我是21年上半年开始准备Elastic认证的，同年6月底参加考试，满分拿证。其实真正开始准备也就是考前两三个月，由于工作确实较忙，真正能用于备考的时间并不是很多。但是由于7月1日考试，考纲和考试所用ES版本即将升级。因此我立下了目标，六月底必须通过考试。

有了目标之后，就是准备考试，备考本身就是枯燥无味的，尤其是最开始也是特别痛苦，遇到不会的知识点首先要花很多时间去理解原理，然后再自己出题，自己实践。尤其是总是被各种事情打断，这个年龄段谁没有一堆事儿？但是，成功的路上也不可能是顺风顺水的。

你可能不仅仅是一个企业的员工，同时也可能是一个儿女、父母。你不仅要工作，还有生活中的各种琐事，要管柴米油盐房租水电，要照顾自己的妻子孩子。忙是每个在努力的路上的人的共同特点，但是这不能成为自己懈怠的理由。不要总感觉自己是最忙的那个，其实，大部分人都比你忙。想要成功，就不要给自己找任何借口，做先做的事儿，你就一定会有时间。

**不要做感动自己的事儿**

提高效率，不要徒耗时间不出结果，结果不会陪着你演戏

## **5 执行力**

学习路线规划完成之后积极落实和执行。

## 6 避免碎片化学习

考试有一点和面试有本质的区别。当你面试一家公司的时候，有的问题可能你只回答一个思路或者回答一个大概就可以了。但是考试是可以量化的。对就是，错就是错，你必须要保证对每一个考点都十分熟悉，对文档特别熟悉。所以大家不要有投机心理或者绞幸心理，觉得应该不会考到。千万不要这么去想。

要保持对每个知识点的熟悉，就要保持学习状态。每天坚持学习至少至少至少每一天都要多多少少看一眼，练一练。这样你才不会忘。但是备考最好是每天能集中一段时间来学习。我的建议是2~3个小时。如果你有更多的时间，那当然更好。尽量避免碎片化学习，这样学习其实效果并不好。

## 7 切忌三天打鱼两天晒网

备战考试最忌讳的一点学几学几天，休息几天。因为这一样很容易把之前学过的东西都遗忘了，简直就是在浪费时间。所以我为什么说集中一段时间用来备考，而不要学一段时间，忙一段儿别的。

千万不要给自己留太长的备考时间。因为这样无形会给自己一种这样的感觉：哎呀，反正还有那么长时间呢，好不容易周末了，我打打游戏吧。或者去旅个游吧。你这样效率只会指数级下降。三天还不如学一天的效果好。

## 8 不要记笔记

首先我并不是说记笔记不好，也不是说记笔记不是一个好习惯。是记笔记是需要时间的。我们每个人每天的备考时间都是非常有限的。需要用到的笔记老师都早已给你提前准备好了。不需要不需要你再去记一遍。如果你真的想加强对知识点的理解，到时候多做几遍题目就行了。这比记笔记效果来的好多了。

## 9 学习周期

半个月 - 2个月

## 10 熟悉文档，此乃备考第一要义！

从现在开始，熟悉文档。文档是考试中唯一可以查阅的资料，熟悉文档指的是要熟悉每个知识点对应的文档的位置，要做到肌肉记忆，不需要思考就能迅速找到文档位置，这能给考试节省大量的时间。注意！是记文档位置，而不是记文档内容！

## 11零基础如何学习

**大部分学员都是零基础**

认证考试课程本身是针对有基础同学。而开设的课程。所以课程讲解速度会比较快，会跳过一些比较基础的内容。但是目前来说，很多报名课程的同学都是零基础的。针对这种情况，不要着急。记住老师下面说的话，一定是没有问题的。

**困难就是用来挑战的**

首先我们目前已经拿到认证考试证书的同学。超过2/3都是零基础的。那么零基础同学想要直接参加认证考试的课程。可能会有一些吃力。尤其是在前期。很多同学都曾经产生过放弃的念头。这是大可不必的，因为大多数同学都是这样的。现在我们吃过的苦，受过的罪都是在为自己创造技术和知识的壁垒。提高自己的不可替代性，你爬过的山头，如果别人没有爬过，那么别人一定就取代不了你，你就更有价值。做更难做的事情才能让你变得更加强大，因为别人做不了。

**零基础具体如何学习**

咱们在报名认证考试课程的时候，都是赠送了elastic理论课程基础的。必过班同学是赠送了Elastic全套课程的。零基础同学在学习过程中如果跟不上课程的节奏，首先要做的事情是根据当前讲解的知识点，找到理论课程。对应的课程讲解。理论课程和认证考试课程最大的区别就是侧重点不一样。讲课速度也不一样。理论课讲究的是细致。速度会慢很多。知识点也会多很多。而考试课程我们侧重实战。针对性很强，速度也比较快。所有和考试不相关的内容都会被删除。认证课程看不懂就尝试找到理论课中对应的知识点，先补一下基础。可能会多花一些时间。但是这是每个人都要经历的过程。成功的路有无数条。失败的路却却只有一个，就是放弃。

如果在学习阶段有任何苦恼，记得要联络老师寻求帮助。

## 12 直播和录播

直播课在每节课后有习题作业，达到要求之后当天课程可以通过，切勿在一节课上死磕，相对来说，直播课督促作用会强一些适合自律性不太好的同学

录播课根据自己的学习情况选择合适时间继续看后面的课程，比较依赖于自身的学习主动性。

# 备考准备事项

## 1 备考服务器方案选择

<table>
	<tr>
	    <th width="15%">方案</th>
	    <th width="20%">优点</th>
	    <th width="30%">缺点</th>  
	    <th width="15%">适合人群</th>
	    <th width="20%" rowspan="5">综合来说，如果不是电脑配置很低又找不来配置高一些的电脑，囊中又比较羞涩。非常不推荐第一种方案，这是最重要的，原则上是考试啥样，咱们备考就啥样，最不容易才能，一旦踩坑就是400美刀的教训，其他三种都可以，视自己情况选择</th>  
	</tr >
	<tr >
	    <td>本地多节点部署</td>
	    <td>1、资源占用率最少，对电脑配置要求最低</td>
	    <td>1、和真实考试环境偏差太大，参加真正考试的时候可能因为环境问题踩坑
        </br>
2、无法跨地区访问</br>
3、环境需要自己搭建</td>
	    <td>对ES和Linux环境本身就很精通，自己电脑配置
不高并且资金不太充足的同学</td>
	</tr>
	<tr>
	    <td>虚拟机方案</td>
	    <td>1、可以很大程度还原考试环境</br>
2、除对电脑硬件有要求外，成本较低</td>
	    <td>1、需要网络架构、虚拟机搭建有一定基础</br>
2、对电脑内存大小要求比较高</br>
3、环境需要自己搭建</br>
4、不支持跨地区访问</br>
5、如果是桥接方案可能会有ip冲突问题，并且相同的配置方案在公司或家里可能因为网关不同而导致服务不可用</td>
	    <td>有计算机网络基础、 
电脑配置比较高、
不经常变更使用地点的同学</td>
	</tr>
	<tr>
	    <td>ECS云服务器</td>
	    <td>1、可随时随地访问，不被使用地点束缚</td>
	    <td>1、价格较贵</br>
2、环境需要自己搭建</br>
3、备考的电脑需要联网环境</td>
	    <td>希望随时随地可以访问
且资金比较充裕的</td>
	</tr>
	<tr>
	    <td>NAS云服务器</td>
	    <td>1、可随时随地访问，不受使用地点约束</br>
2、环境是预安装好的</br>
3、价格较为便宜</td>
	    <td>1、服务器为共享隔离服务器，仅适用于备战考试，不适合部署其他服务</br>
2、备考的电脑需要联网环境</td>
	    <td>搞不定环境问题
不想在环境上耽误时间
希望随时随地可以访问服务的</td>
	</tr>
</table>

## 2 备考环境集群架构

自建虚拟机集群需遵循以下网络拓扑。课程讲解的时候也会按照下面拓扑进行教学。集群至少要有两个，推荐值为三个。节点数至少为四个。推荐值为四个。DS Cluster保证至少一个节点。推荐值一个节点。CFG Cluster建议两个集群，推荐值为两个集群，其中要至少保证一个集群有两个节点。

每个节点的IP地址根据自己的网络环境。动态修改每个人的一直都是不一样的。

推荐的集群配置为，DSL_Cluster：1个节点。CFG_Cluster_1：2个节点，CFG_Cluster_2：1个节点。这是在保证符合考试要求和课程讲解的前提下的最小节点配置，如果节点过多，配置起来较为麻烦。没有太大意义，只会耽误自己时间。写点数少于这个配置，考题无法完成。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/c7e43f6f12ab4527b807d5b62e5d3260.png)

## 3 虚拟机方案

### 3.1 不同主机配置的集群拓扑选择

原则上说，备考环境越接近真实环境越好，每个节点建议2G内存，如果内存不够可以调成1G，但是默认1G内存启动会报错，需要修改jvm.options中默认要求的jvm最小值。如果内存足够不建议在环境上花太多时间，因为这并非考试内容，cfg-cluster必须至少有一个多节点集群，因为考点中包含关于集群发现的内容。就算你内存足够，也不建议配置过多节点，因为每次启动你的宿主机你都需要启动每个节点的服务，会浪费你的时间。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/28/1647945143066/695f99d84e644a39b3bf61c22794fdbd.png)

### 3.2 使用自建虚拟机

#### 3.2.1 操作系统要求：

- 版本：CentOS 7
- RAM：建议2G
- 下载：课件

#### 3.2.2 Java环境：

- 版本：1.8
- 下载：
  - 程序员大礼包：https://www.programmer-box.com/?ref=jdk_1.8
  - Java I tell you：https://www.injdk.cn/
  - Arm JDK for M1：https://www.azul.com/downloads/?version=java-8-lts&os=macos&package=jdk
- 安装：略（自行百度）
- 检查：java -version

#### 3.2.3 Elasticsearch环境：

- 版本：7.13.x
- 下载：https://www.elastic.co/cn/downloads/past-releases#elasticsearch
- 安装：理论课程
- 检查：访问 `server_ip:9200`（视具体配置的ip和端口）

#### 3.2.4 vim编辑器（考试环境中已安装，根据个人习惯选择是否安装）

**安装：**

```
yum install vim
```

#### 3.2.5 网络配置

**编辑网卡**：

```
vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

**修改配置文件：**

```
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="none" #关闭DHCP
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="6dcded77-ba54-4f70-a16c-80535656ba86"
DEVICE="ens33"
ONBOOT="yes"
IPADDR="192.168.3.81" #修改每个节点的ip地址
PREFIX="24"
GATEWAY="192.168.3.1"
DNS1="114.114.114.114"
DOMAIN="8.8.8.8"
IPV6_PRIVACY="no"
```

保存并重启网络：

```
service network restart
```

如果失败，执行

```
yum install net-tools
```

#### 3.2.6 新手常见问题解答

##### **1 禁用Swapping：**

```
bootstrap.memory_lock: true
```

##### **2 文件描述符**

问题描述：引导检查报错：未开启内存锁

问题解释：Elasticsearch 使用了很多文件描述符或文件句柄。耗尽文件描述符可能是灾难性的，并且很可能会导致数据丢失。确保将运行 Elasticsearch 的用户的打开文件描述符数量限制增加到 65,536 或更高。

解决办法：

```
vim /etc/security/limits.conf
# 添加以下内容
* soft nofile 65536
* hard nofile 65536
* soft nproc 32000
* hard nproc 32000
* hard memlock unlimited
* soft memlock unlimited

vim /etc/systemd/system.conf ，分别修改以下内容。
DefaultLimitNOFILE=65536
DefaultLimitNPROC=32000
DefaultLimitMEMLOCK=infinity

ulimit -n 65535(需使用root账号)
```

##### **3 虚拟内存**

**问题描述**：引导检查报错 max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]

**问题解释**：5.0版本以后ES使用mmapfs作为默认的文件系统存储类型。可以通过配置index.store.type来设置ES默认的文件系统存储类型。ES mmapfs默认使用一个目录来存储它的索引。操作系统对 mmap 计数的默认限制可能太低，这可能会导致内存不足异常.

解决办法：

修改文件系统

```
Niofs(非阻塞文件系统)	mmapfs(内存映射文件系统)
配置:index.store.type: niofs
```

使用root运行以下命令：

```
sysctl -w vm.max_map_count=262144
```

永久生效：

```
vi /etc/sysctl.conf
vm.max_map_count=262144

grep vm.max_map_count /etc/sysctl.conf
```

##### 4 线程数

**问题描述**：max number of threads [1024] for user [elasticsearch] is too low, increase to at least [2048]

问题解释：ES 使用多个线程池来进行不同类型的操作。重要的是它能够在需要时创建新线程。确保 Elasticsearch 用户可以创建的线程数至少为 4096。

**解决办法**

```
在启动es服务之前使用root账户执行
ulimit -u 4096
```

或

```
vim /etc/security/limits.conf
设置nproc为4096
```

或

```
vim /etc/security/limits.d/90-nproc.conf 
修改如下内容（注意星号）：
* soft nproc 1024  =>  * soft nproc 4096
```

##### 5 IPv4 forwarding

**问题描述**：WARNING: IPv4 forwarding is disabled. Networking will not work.

问题解释：翻译即可

**解决办法**：

```
vi /etc/sysctl.conf
net.ipv4.ip_forward=1
restart network && systemctl restart docker
sysctl net.ipv4.ip_forward
```

##### 6 内存不足

**问题描述**：error='Cannot allocate memory'

问题解释：ES 5.x+堆内存大小默认配置为2G     ES 7.x+默认4G

**解决办法**：

```
//JVM一般为物理内存一半
-e "ES_JAVA_OPTS=-Xms512m -Xmx512m"
```

### 3.3 使用共享虚拟机

#### 3.3.1 概述

考试所需Linux集群并非考点。但是我们备考这是必要条件，遵循最小化学习路线。和考试无关的内容我们能跳过则跳过。不能跳过则以最小代价来实现。如果你选择了虚拟机方案，建议直接下载老师共享的虚拟机文件，共享的虚拟机文件里已经集成好了所有环境以及配置等等，下载好导入即可使用，需要集群环境，只需克隆多个节点，改一下IP地址即可。IP地址可根据目前你的网络类型是桥接还是nat动态决策。保证多个节点在同一个内网环境下即可。

#### 3.3.2 共享文件下载地址

虚机文件（已安装Java环境和ES服务，路径：/usr/local ）

**链接**: https://pan.baidu.com/s/1c3CKlDHz7bo991MW1HSJBg 	提取码: s32e，

**账号**：root

**密码**：123456

开袋即食，多节点克隆即可

### 3.4 演示

### 3.5 创建elastic账号：

创建账号：useradd elastic
设置es账号的密码：passwd elastic
为账号赋予目录权限：chown -R elastic:elastic {{espath}}

## 4 云服务器方案

### 4.1 NAS

### 4.2 ECS

自建ES集群环境，非内网环境需要通过外网配置集群。

## 5 主机环境

### 5.1 Kibana

- 版本：7.13.x
- 下载：
  - http://www.elastic.show/download/Elasticsearch/7.13/ (使用迅雷下载)
  - https://www.elastic.co/cn/downloads/past-releases#elasticsearch
- 安装：课程
- 修改配置项：
  - server.host: "server_ip:port"
  - server.port: 5601

### 5.2 远程终端

- Windows：xshell
- MacOS：
  - ZenTermLite
  - Termius
- all：[electerm](https://github.com/electerm/electerm)
  - 学员评价：这个软件目前是一款开源的虚拟机连接工具，跟大名鼎鼎的Xshell一样好用，软件设计上更加简洁，大气，连接配置也非常方便；只需要配置3个信息（IP地址，用户名和密码）即可连接；软件还提供了命令批量导入功能，比如我们在安装讲集群的时候同时打开三个界面，我们只需要在批量输入框中输入想要的命令，就可以实现在多个界面同时运行，大大减少了平时工作过程中的重复操作，大大提升了虚拟机的体验和工作的效率，是虚拟机运维的一款神奇；目前此软件用的比较少，但是一旦用少你会爱上它；

## 4.3 浏览器

Chrome浏览器（必须是Chrome，考试的时候必须使用谷歌浏览器，建议备考的时候和考试环境保持一致。）

# 节点

#### 此小节开始，进入考试考点范围，备考须知：

- 老师微信：elastic1
- 知识星球：[Elastic开源社区](https://t.zsxq.com/urJmqFM "点击免费加入知识星球")，用以打卡和布置作业，以及资源分享和下载
- 同时欢迎关注Elastic公众号：[Elasticsearhch之家](https://img-blog.csdnimg.cn/6d39b63d8bec499f9719e52ff0ab0072.png "点击查看二维码")（点击关注），更多干货，每日更新！关注有惊喜！
- 备考群：ECE备战勇士群，联系老师进群
- CSDN：[Elastic开源社区](elastic-cn.blog.csdn.net)
- 社区：[Elastic开源社区](https://bbs.csdn.net/forums/es?category=0 "点击加入Elastic开源社区")

## 1 文档位置：

[Set Up Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/setup.html) > [Configuring Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/settings.html#config-files-location) > [Node](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/modules-node.html)

## 2 主从模式（Leader/Follower）

Elasticsearch使用的主从架构模式，其实除此之外，还可以使用分布式哈希表（DHT），其区别在于：

* 主从模式适合节点数量不多，并且节点的状态改变（加入集群或者离开集群）不频繁的情况。
* 分布式哈希表支持每小时数千个节点的加入或离开，响应约为4-10跳。

ES的应用场景一般来说单个集群中一般不会有太多节点（一般来说不超过一千个），节点的数量远远小于单个节点（只的是主节点）所能维护的连接数。并且通常主节点不必经常处理节点的加入和离开，处于相对稳定的对等网络中，因此使用主从模式。

## 3 节点角色：

### 3.1 主节点（active master）

* 避免重负载：主节点负责轻量级集群范围的操作，例如创建或删除索引、跟踪哪些节点是集群的一部分以及决定将哪些分片分配给哪些节点。拥有一个稳定的主节点对于集群健康很重要。当选的主节点拥有履行其职责所需的资源，这对于集群的健康非常重要。如果所选的主节点承载了其他任务，那么集群将不能很好地运行。避免 master 被其他任务超载的最可靠方法是将所有符合 master 的节点配置为仅具有 master 角色的专用 master 节点，使它们能够专注于管理集群。专用master节点仍将充当协调节点，将请求从客户端路由到集群中的其他节点，但是不要以负载均衡器的目的而设置候选节点。
* 一般来说，如果小型或轻负载集群的主节点具有其他角色和职责，则其可能运行良好，但是一旦您的集群包含多个节点，使用专用的主节点通常是有意义的。
* 任何不是 `voting-only`的 `master-eligible`节点都可以被选举为 `active master`。
* 主节点必须有一个 `path.data`目录，其内容在重启后仍然存在，就像数据节点一样，因为这是存储集群元数据的地方。集群元数据描述了如何读取存储在数据节点上的数据，因此如果丢失，则无法读取存储在数据节点上的数据。
* 高可用性 (HA) 集群需要至少三个候选节点，其中至少两个不是仅投票节点。这样即使其中一个节点发生故障，也可以保证剩下的节点能够选举出一个主节点**。**

##### master 候选节点/投票节点（master-eligible，有时候也叫master节点）

默认情况下，master-eligible节点是那些在集群状态发布期间参与选举并执行某些任务的节点，配置了master角色的节点都是有效的投票节点，可以参与选举也可以投票

任何不是[仅投票](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/modules-node.html#voting-only-node)节点的主合格节点都可以通过[主选举过程选举](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/modules-discovery.html)成为主节点**。**

**配置主节点（有选举和被选举权）：**

```
 node.roles: [ master,xx,xx,xx ]
```

**配置专用主节点（dedicated master-eligible node）：**

```
 node.roles: [ master ]
```

**配置仅投票节点（只有选举权，没有被选举权，这样的节点可以同时充当数据节点避免资源浪费）：**

```
 node.roles: [ data, master, voting_only ]
```

##### data：数据节点

数据节点保存包含已编入索引的文档的分片。数据节点处理数据相关操作，如 CRUD、搜索和聚合。这些操作是 I/O 密集型、内存密集型和 CPU 密集型的。监控这些资源并在它们过载时添加更多数据节点非常重要。

**配置数据节点：**

```
 node.roles: [ data, xxx ]
```

##### ingest：预处理节点

预处理节点有点类似于logstash的消息管道，所以也叫ingest pipeline，常用语一些数据写入之前的预处理操作，比如去除空格、split等操作，常和update_by_query、reindex等一起考

##### remote_cluster_client：远程节点，跨集群搜索必须的角色

具有 `remote_cluster_client`角色的节点，使其有资格充当远程客户端

## 4 配置方法：

node.roles: [ master, data ]

## 5 注意：

没有 `data`角色的节点在启动时如果在磁盘上找到任何分片数据将拒绝启动，而没有角色 `master`和 `data`角色的节点如果在启动时在磁盘上有任何索引元数据将拒绝启动。

可以通过调整其 `elasticsearch.yml`文件并重新启动它来更改节点的角色 。这称为重新调整节点的用途。为了满足上述对意外数据的检查，您必须执行一些额外的步骤来准备节点，以便在没有 `data`或 `master`角色的情况下启动节点时重新调整用途。

* **如果您想通过删除** `data`角色来重新调整数据节点的用途，那么您应该首先使用[分配过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/allocation-filtering.html)将所有分片数据安全地迁移到集群中的其他节点上。
* **如果您想重新调整节点的用途，使其既没有** `data`也没有 `master`角色，那么最简单的方法是启动一个带有空数据路径和所需角色的全新节点。您可能会发现首先使用[分配过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/allocation-filtering.html)将分片数据迁移到集群中的其他位置是最安全的 。

如果无法执行这些额外步骤，那么您可以使用该[`elasticsearch-node repurpose`](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/node-tool.html#node-tool-repurpose)工具删除任何阻止节点启动的多余数据。

# 分片

## 1 分布式的好处

* 高可用性：集群可容忍部分节点宕机而保持服务的可用性和数据的完整性
* 易扩展：当集群的性能不满足业务要求时，可以方便快速的扩容集群，而无需停止服务。
* 高性能：集群通过负载均衡器分摊并发请求压力，可以大大提高集群的吞吐能力和并发能力。

## 2 分片分配策略

* 一个索引包含一个或多个分片，在7.0之前默认五个主分片，每个主分片一个副本；在7.0之后默认一个主分片。副本可以在索引创建之后修改数量，但是主分片的数量一旦确定不可修改，只能创建索引
* 每个分片都是一个Lucene实例，有完整的创建索引和处理请求的能力
* ES会自动再nodes上做分片均衡 shard reblance
* 一个doc不可能同时存在于多个主分片中，但是当每个主分片的副本数量不为一时，可以同时存在于多个副本中。
* `每个主分片和其副本分片`或者 `相同的副本`不能同时存在于同一个节点上。

# 健康值检查及故障诊断

## 1 集群健康值

### 1.1 健康状态

* 绿色：所有分片都可用
* 黄色：至少有一个副本不可用，但是所有主分片都可用
* 红色：至少有一个主分片不可用，数据不完整

### 1.2 健康值检查

* GET _cat/health
* GET _cluster/health

## 2 集群故障诊断  ★

### 2.1 Cat APIs：

**文档地址：**[REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/cat.html) > [Compact and aligned text (CAT) APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/cat.html#cat)

**常用APIs：**

* _cat/indices?health=yellow&v=true：查看当前集群中的所有索引
* _cat/health?v=true：查看健康状态
* _cat/nodeattrs：查看节点属性
  * 常见考点：分片分配感知、冷热集群
* _cat/nodes：查看集群中的节点
* _cat/shards
  * _cat/shards/<target>** 查看指定索引的分片分配**
  * _cat/shards?h=index,shard,prirep,state,unassigned.reason 查看指定属性分片分配

### 2.2 Cluster APIs

**文档地址**：[REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/cat.html) > [Cluster APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/cluster.html)

**常用APIs**：

* _cluster/allocation/explain
  * 可用于诊断分片未分配原因
* _cluster/health/<target>
  * 检查集群状态

### 2.3 索引未分配的原因

* ALLOCATION_FAILED: 由于分片分配失败而未分配
* CLUSTER_RECOVERED: 由于完整群集恢复而未分配.
* DANGLING_INDEX_IMPORTED: 由于导入悬空索引而未分配.
* EXISTING_INDEX_RESTORED: 由于还原到闭合索引而未分配.
* INDEX_CREATED: 由于API创建索引而未分配.
* INDEX_REOPENED: 由于打开闭合索引而未分配.
* NEW_INDEX_RESTORED: 由于还原到新索引而未分配.
* NODE_LEFT: 由于承载它的节点离开集群而取消分配.
* REALLOCATED_REPLICA: 确定更好的副本位置并取消现有副本分配.
* REINITIALIZED: 当碎片从“开始”移回“初始化”时.
* REPLICA_ADDED: 由于显式添加了复制副本而未分配.
* REROUTE_CANCELLED: 由于显式取消重新路由命令而取消分配.

**##### **

# 索引

## 1 概念

略（见知识库或Elastic Stack）

## 2 索引别名：aliases ★

### 2.1 文档地址：

* ##### [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) > [Index APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices.html) > [Aliases](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-aliases.html)
* ##### [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) > [Index APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices.html) > [Create Index](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-create-index.html)

### 2.2 别名作用：

* 保护索引：索引相对于调用者是隐藏的。
* 别名可以结合如 `reindex`,`update_by_query`,`rollover_index`,`ILM`等完成一系列对索引的切换操作。

### 2.3 语法

```
 POST /_aliases
```

### 2.4 注意

* 一个索引可以绑定多个别名，一个别名也可以绑定多个索引
* 别名不能和索引名相同

## 3 索引映射：mappings ★：

## 4 索引级设置：settings ★：

### 4.1 文档地址

##### [Elasticsearch Guide [7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Index modules](https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-modules.html#_static_index_settings)

### 4.2 静态设置：

只能在索引创建时或在关闭状态的索引上设置的。

常见设置：修改主分片数量 `index.number_of_shards`

### 4.3 动态设置

**在任何时候都可以修改的设置，使用 `update-index-setting`进行操作**

**常见设置：修改副本分片数量 `number_of_replicas`**

## 5 重建索引：Reindex

### 5.1 文档地址：

[Elasticsearch Guide 7.13]]([https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html)) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Document APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/docs.html) » Reindex API

### 5.2 注意事项：

Reindex不会把旧索引的Mapping信息和Setting信息同步到新索引，所以需要我们手工创建Mapping

## 6 索引模板：Index Template

### 6.1 文档地址：

* ##### [[Elasticsearch Guide 7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Index templates](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-templates.html)

## 7 索引的CRUD

### 7.1 REST API

* PUT
* DELETE
* POST
* GET

### 7.2 四种写操作：

* **create：如果在PUT数据的时候当前数据已经存在，则数据会被覆盖，如果在PUT的时候加上操作类型create，此时如果数据已存在则会返回失败，因为已经强制指定了操作类型为create，ES就不会再去执行update操作。比如：PUT /pruduct/***create/1/ （ 老版本的语法为  PUT /pruduct/*doc/1/_create ）指的就是在索引product中强制创建id为1的数据，如果id为1的数据已存在，则返回失败。
* delete：删除文档，ES对文档的删除是懒删除机制，即标记删除。
* index：在ES中，写入操作被称为Index，这里Index为动词，即索引数据为将数据创建在ES中的索引，后面章节中均称之为“索引数据”。
* update：执行partial update（全量替换，部分替换）

# 映射：mappings

## 1 映射的作用与含义

## 2 自动映射与手动映射

## 3 创建mapping的技巧

## 4 映射参数：

* **文档地址：**[Mapping](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping.html) > [Mapping parameters](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping-params.html)
* **重点备考范围：**
  * **[`analyzer`](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/analyzer.html)**
  * **search_analyser：搜索词分词器**
  * **[`boosting`](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping-boost.html)**
  * [`fielddata`](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/fielddata.html)
  * [`fields`](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/multi-fields.html)

## 5 ES的数据类型

* **文档地址：**[Mapping](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping.html) > [Field data types](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping-types.html)
* **常用类型：**[text](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/text.html)、[boolean](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/boolean.html)、[nested](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/nested.html)、[keyword](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/keyword.html#keyword-field-type)、[long](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/number.html)

## 6 Keyword的坑

## 7 嵌套类型：Nested

## 8 运行时字段：Runtime fields ★

## 9 自动映射模板：Dynamic Template

* **动态模板★：**[Mapping](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/mapping.html) > [Dynamic mapping](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/dynamic-mapping.html) > [Dynamic templates](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/dynamic-templates.html)

## 10 重点备考范围：

* Analysis
* Boosting
* Nested
* Dynamic template

# 分词器（Analysis）

考纲中不包含中文分词器

## 1 分词器的作用

### 1.1 发生时期

**Index Time**：即数据的在索引期间进行分词操作

## 2 分词器组成

### 2.1 字符过滤器: char_filter

##### 文档位置: [Text analyis](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/analysis.html) > [Character filters reference](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/analysis-charfilters.html)

* 过滤字符
* 替换字符
* 字符映射

### 2.2 词项过滤器：filter

* Lowcase
* Uppercase
* Trim
* Synonym ★

### 2.3 切词器：tokenizer

* whitespace ★



* standard 按照空格切割



* english 语气词去掉



## 3 自定义分词器

### 3.1 用法

```
PUT <index>
{
  "settings": {
    "analysis": {
      //定义分词器
    }
  },
  "mappings": {
    //使用分词器
  }
}
```

```
# 设置type 为custom告诉Elasticsearch我们正在定义一个定制分析器。将此与配置内置分析器的方式进行比较：type 将设置为内置分析器的名称，如 standard 或 simple
PUT /test_analysis
{
	"settings": {
		"analysis": {
			"char_filter": {
				"test_char_filter": {
					"type": "mapping",
					"mappings": [
						"& => and",
						"| => or"
					]
				}
			},
			"filter": {
				"test_stopwords": {
					"type": "stop",
					"stopwords": ["is", "in", "at","the","a","for"]
				}
			},
			"analyzer": {
				"my_custom_analyzer": {
					"char_filter": [
					"emticons"
					],
					"tokenizer": "punctuation",
					"filter": [
						"lowercase",
						"english_stop"
					]
				}
			},
			"tokenizer": {
				"punctuation": {
					"type": "pattern",
					"pattern": "[ .,!?]"
				}
			},			
		}
	}
}
```



# 检索

## 1 上下文对象

使用query关键字进行检索，倾向于相关度搜索，故需要计算评分。搜索是Elasticsearch最关键和重要的部分。

## 2 相关度评分：_score

### 2.1 概念

相关度评分用于对搜索结果排序，评分越高则认为其结果和搜索的预期值相关度越高，即越符合搜索预期值。在7.x之前相关度评分默认使用TF/IDF算法计算而来，7.x之后默认为BM25。在核心知识篇不必关心相关评分的具体原理，只需知晓其概念即可。

### 2.2 排序规则

如果没有指定排序字段，则默认按照评分高低排序，相关度评分为搜索结果的排序依据，默认情况下评分越高，则结果越靠前。

### 2.3 评分规则

* 词频（TF term frequency ）：关键词在每个doc中出现的次数，词频越高，评分越高
* 反词频（ IDF inverse doc frequency）：关键词在整个索引中出现的次数，反词频越高，评分越低
* 每个doc的长度，越长相关度越低

## 3 元数据：_source

### 3.1 数据源过滤器：

Including：结果中返回哪些field

Excluding：结果中不要返回哪些field，不返回的field不代表不能通过该字段进行检索，因为元数据不存在不代表索引不存在

1. **在mapping中定义过滤：支持通配符，但是这种方式不推荐，因为mapping不可变**
   ```
   PUT product
   {
     "mappings": {
       "_source": {
         "includes": [
           "name",
           "price"
         ],
         "excludes": [
           "desc",
           "tags"
         ]
       }
     }
   }
   ```
2. **常用过滤规则**
   * "_source": "false",
   * "_source": "obj.*",
   * "_source": [ "obj2.*", "obj2.*" ],
   * "_source": { "includes": [ "obj2.*", "obj2.*" ], "excludes": [ "*.description" ] }

## 4 Query String ☆

##### 经常用到，但是并非考点

* #### 查询所有：

  GET /product/_search
* #### 带参数：

  GET /product/_search?q=name:xiaomi
* #### 分页：

  **GET /product/_search?from=0&size=2&sort=price:asc**
* #### 精准匹配 exact value

  GET /product/_search?q=date:2021-06-01

## 5 全文检索-Fulltext query ★★

### 5.1 文档地址

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl.html) » Full text queries

### 5.2 语法

```
GET <index>/_search
{
  "query": {
    "<fulltext query type>": {
    ***
    }
  }
}
```

* #### match：匹配包含某个term的子句 搜索词和字段都会被分词  ★
* #### match_all：匹配所有结果的子句
* #### multi_match：多字段查询 ★

  ##### 文档地址：[Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl.html) > [Full text query](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/full-text-queries.html) > [Multi_match](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl-multi-match-query.html#query-dsl-multi-match-query)


  * ##### multi_match和_source区别

    * multi_match：从哪些字段中检索，指的是查询条件
    * _source：查询的结果包含哪些字段，指的是元数据
  * ##### best_fields、most_fields、cross_fields

    * best_fields：单个字段的得分权重大，对于同一个query，单个field匹配更多的term，则优先排序。
    * most_fields：单个查询的得分权重大，如果一次请求中，对于同一个doc，匹配到某个term的field越多，则越优先排序。
    * cross_fields:
  * ##### dix_max查询（Disjunction Max Query）：

    将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回
  * ##### tie_breaker：

    取值范围 [0,1]，其中 0 代表使用 dis_max 最佳匹配语句的普通逻辑，1表示所有匹配语句同等重要。最佳的精确值需要根据数据与查询调试得出，但是合理值应该与零接近（处于 0.1 - 0.4 之间），这样就不会颠覆 dis_max 最佳匹配性质的根本。
* #### match_phrase：短语查询，每个词项都会被分词  ★


  * match_phrase会分词
  * 被检索字段必须包含match_phrase中的所有词项并且顺序必须是相同的
  * 被检索字段包含的match_phrase中的词项之间不能有其他词项
* #### prefix：前缀搜索 ☆

  ##### 概念：以xx开头的搜索，不计算相关度评分。

  ##### 语法：


  ```
  GET <index>/_search
  {
    "query": {
      "prefix": {
        "<field>": {
          "value": "<word_prefix>"
        }
      }
    }
  }
  index_prefixes: 默认   "min_chars" : 2,   "max_chars" : 5 
  ```
* #### match_phrase_prefix：短语前缀 ☆

  ##### 概念：

  **	**match_phrase_prefix与match_phrase相同,但是它多了一个特性,就是它允许在文本的最后一个词项(term)上的前缀匹配,如果 是一个单词,比如a,它会匹配文档字段所有以a开头的文档,如果是一个短语,比如 "this is ma" ,他会先在倒排索引中做以ma做前缀搜索,然后在匹配到的doc中做match_phrase查询,(网上有的说是先match_phrase,然后再进行前缀搜索, 是不对的)

  ##### 参数


  * analyzer 指定何种分析器来对该短语进行分词处理
  * max_expansions 限制匹配的最大词项
  * boost 用于设置该查询的权重
  * slop 允许短语间的词项(term)间隔：slop 参数告诉 match_phrase 查询词条相隔多远时仍然能将文档视为匹配 什么是相隔多远？ 意思是说为了让查询和文档匹配你需要移动词条多少次？
* #### 通配符：wildcard ☆

  ##### 概念：通配符运算符是匹配一个或多个字符的占位符。例如，*通配符运算符匹配零个或多个字符。您可以将通配符运算符与其他字符结合使用以创建通配符模式。

  ##### 注意：


  * **通配符匹配的也是term，而不是field**

  ##### 语法：

  ```
  GET <index>/_search
  {
    "query": {
      "wildcard": {
        "<field>": {
          "value": "<word_with_wildcard>"
        }
      }
    }
  }
  ```

  #### 分页

  ##### size默认为10，考试可能会明确指出size的值，也可能不会

  ```
  GET <index>/_search
  {
    "from": 0,
    "size": 2,  
    "query": {
      "match_all": {}
    }
  }
  ```

  #### 排序

  ```
  GET task5/_search
  {
    "query": {
      //xxx
    },
    "sort": [
      {
        "field_a": {
          "order": "asc"
        }
      },
      {
        "_score": {
          "order": "desc"
        }
      }
    ]
  }
  ```

  #### 高亮

  ```
  GET task5/_search
  {
    "query": {
      //xxx
    },
    "highlight": {
      "fields": {
        "title": {
          "pre_tags": [
            "<b>"
          ],
          "post_tags": [
            "</b>"
          ]
        }
      }
    }
  }
  ```

## 6 精准查询-Term query

### 6.1 文档地址

### 6.2 查询函数

* #### term：匹配和搜索词项完全相等的结果

  * term和match_phrase区别:
    match_phrase 会将检索关键词分词, match_phrase的分词结果必须在被检索字段的分词中都包含，而且顺序必须相同，而且默认必须都是连续的
    term搜索不会将搜索词分词
  * term和keyword区别
    term是对于搜索词不分词,
    keyword是字段类型,是对于source data中的字段值不分词
* #### terms：匹配和搜索词项列表中任意项匹配的结果
* #### range：范围查找

## 7 过滤器-Filter

```
GET _search
{
  "query": {
    "constant_score": {
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}
```

* filter：query和filter的主要区别在： filter是结果导向的而query是过程导向。query倾向于“当前文档和查询的语句的相关度”而filter倾向于“当前文档和查询的条件是不是相符”。即在查询过程中，query是要对查询的每个结果计算相关性得分的，而filter不会。另外filter有相应的缓存机制，可以提高查询效率。

## 8 组合查询-Bool query

### 8.1 文档地址

##### Query DSL > Compound queries > [Boolean](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl-bool-query.html)

### 8.2 自查询函数

**bool**：可以组合多个查询条件，bool查询也是采用more_matches_is_better的机制，因此满足must和should子句的文档将会合并起来计算分值

* **must**：必须满足子句（查询）必须出现在匹配的文档中，并将有助于得分。
* **filter**：过滤器 不计算相关度分数，cache☆子句（查询）必须出现在匹配的文档中。但是不像 must查询的分数将被忽略。Filter子句在[filter上下文](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html)中执行，这意味着计分被忽略，并且子句被考虑用于缓存。
* **should**：可能满足 or子句（查询）应出现在匹配的文档中。
* must_not：必须不满足 不计算相关度分数  not子句（查询）不得出现在匹配的文档中。子句在[过滤器上下文](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html)中执行，这意味着计分被忽略，并且子句被视为用于缓存。由于忽略计分，0因此将返回所有文档的分数。

minimum_should_match：参数指定should返回的文档必须匹配的子句的数量或百分比。如果bool查询包含至少一个should子句，而没有must或 filter子句，则默认值为1。否则，默认值为0

# 多字段查询：Multi_match

## 1 文档地址：

[Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl.html) > [Full text query](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/full-text-queries.html) > [Multi_match](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/query-dsl-multi-match-query.html#query-dsl-multi-match-query)

## 2 概念

多字段检索，是组合查询的另一种形态，考试的时候如果考察多字段检索，并不一定必须使用multi_match，使用bool query，只要结果正确亦可，除非题目中明确要求（目前没有强制要求过）

## 3 语法

```
 GET <index>/_search
 {
   "query": {
     "multi_match": {
       "query": "<query keyword>",
       "type": "<multi_match_type>",
       "fields": [
         "<field_a>",
         "<field_b>"
       ]
     }
   }
 }
```

## 4 误区：multi_match和_source区别

* **multi_match：从哪些字段中检索，指的是查询条件**
* **_source：查询的结果包含哪些字段，指的是元数据**

## 5 multi_match type：best_fields、most_fields、cross_fields

* best_fields：单个字段的得分权重大，对于同一个query，单个field匹配更多的term，则优先排序。
* most_fields：单个查询的得分权重大，如果一次请求中，对于同一个doc，匹配到某个term的field越多，则越优先排序。
* cross_fields：将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回

### 5.1 dix_max查询（Disjunction Max Query）：

将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回

### 5.2 tie_breaker：

取值范围 [0,1]，其中 0 代表使用 dis_max 最佳匹配语句的普通逻辑，1表示所有匹配语句同等重要。最佳的精确值需要根据数据与查询调试得出，但是合理值应该与零接近（处于 0.1 - 0.4 之间），这样就不会颠覆 dis_max 最佳匹配性质的根本。

## 6 权重

# 聚合查询 ★

## 1 文档位置

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Aggregations](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/search-aggregations.html)

## 2 概念 ☆

**如果是理论学习要求概念是必须理解的，但认证考试的目的性很强，人的精力有限，要有侧重。**

**聚合（aggs）不同于普通查询，是目前学到的第二种大的查询分类，第一种即“query”，因此在代码中的第一层嵌套由“query”变为了“aggs”。**用于进行聚合的字段必须是exact value，分词字段不可进行聚合，对于text字段如果需要使用聚合，需要开启fielddata，但是通常不建议，因为fielddata是将聚合使用的数据结构由磁盘（doc_values）变为了堆内存（field_data），大数据的聚合操作很容易导致OOM，详细原理会在进阶篇中阐述。

## 3 聚合分类  ★

认证考试不会考理论问题，不会去问你聚合分配有哪些，通常考试题目会穿插多个知识点，需要你快速判断应该用手段解决问题。三种聚合分类皆为考点，题目中出现的概率大致相同，所以要做到对三种不同的聚合分类心中有数。

### 3.1 分桶聚合（Bucket agregations）

类比SQL中的group by的作用，主要用于统计不同类型数据的数量

### 3.2 指标聚合（Metrics agregations）

主要用于最大值、最小值、平均值、字段之和等指标的统计

### 3.3 管道聚合（Pipeline agregations）

用于对聚合的结果进行二次聚合，如要统计绑定数量最多的标签bucket，就是要先按照标签进行分桶，再在分桶的结果上计算最大值。

## 4 语法

Aggretations 是ES体系的第二种查询，体现在语法上即在顶层查询由 `query`变为了 `aggs`, 这种基本语法还是要记住，原则上简单的语法和api最好都是记住，能不翻阅文档尽量不翻阅文档，因为即便再熟悉完档，也是需要时间，而且还要受制于网略，考试的时候网络对你的影响可能比你想象的还要大。

在聚合查询的时候，默认会返回元数据，即hits数据，考试大概率会明确要求是否需要元数据，按照题目要求即可，可通过 `size = 0`来设置不返回任何元数据。

```
 GET product/_search
 {
   "size": 0, 
   "aggs": {
     "<aggs_name>": {
       "<agg_type>": {
         "field": "<field_name>"
       }
     }
   }
 }
```

aggs_name：聚合函数的名称

agg_type：聚合种类，比如是桶聚合（terms）或者是指标聚合（avg、sum、min、max等）

field_name：字段名称或者叫域名。

## 5 桶聚合 ★

场景：用于统计不同种类的文档的数量，可进行嵌套统计。

函数：terms

注意：聚合字段必须是exact value，如keyword

## 6 指标聚合 ★

场景：用于统计某个指标，如最大值、最小值、平均值，可以结合桶聚合一起使用，如按照商品类型分桶，统计每个桶的平均价格。

函数：平均值：Avg、最大值：Max、最小值：Min、求和：Sum、详细信息：Stats、数量：Value count

## 7 管道聚合 ★

场景：用于对聚合查询的二次聚合，如统计平均价格最低的商品分类，即先按照商品分类进行桶聚合，并计算其平均价格，然后对其平均价格计算最小值聚合

函数：Min bucket：最小桶、Max bucket：最大桶、Avg bucket：桶平均值、Sum bucket：桶求和、Stats bucket：桶信息

注意：buckets_path为管道聚合的关键字，其值从当前聚合统计的聚合函数开始计算为第一级。比如下面例子中，my_aggs和my_min_bucket同级，				my_aggs就是buckets_path值的起始值。

```
 GET product/_search
 {
   "size": 0, 
   "aggs": {
     "my_aggs": {
       "terms": {
         ...
       },
       "aggs": {
         "my_price_bucket": {
           ...
         }
       }
     },
     "my_min_bucket":{
       "min_bucket": {
         "buckets_path": "my_aggs>price_bucket"
       }
     }
   }
 }
```

## 8 嵌套聚合

### 8.1 语法：

```
 GET product/_search
 {
   "size": 0,
   "aggs": {
     "<agg_name>": {
       "<agg_type>": {
         "field": "<field_name>"
       },
       "aggs": {
         "<agg_name_child>": {
           "<agg_type>": {
             "field": "<field_name>"
           }
         }
       }
     }
   }
 }
```

用途：用于在某种聚合的计算结果之上再次聚合，如统计不同类型商品的平均价格，就是在按照商品类型桶聚合之后，在其结果之上计算平均价格

## 9 聚合和查询的相互关系

### 9.1 基于query或filter的聚合

**语法：**

```
 GET product/_search
 {
   "query": {
     ...
   }, 
   "aggs": {
     ...
   }
 }
```

注意：以上语法，执行顺序为先query后aggs，顺序和谁在上谁在下没有关系。query中可以是查询、也可以是filter、或者bool query

### 9.2 基于聚合结果的查询、

```
 GET product/_search
 {
   "aggs": {
     ...
   },
   "post_filter": {
     ...
   }
 }
```

注意：以上语法，执行顺序为先aggs后post_filter，顺序和谁在上谁在下没有关系。

### 9.3 查询条件的作用域

```
 GET product/_search
 {
   "size": 10,
   "query": {
     ...
   },
   "aggs": {
     "avg_price": {
       ...
     },
     "all_avg_price": {
       "global": {},
       "aggs": {
         ...
       }
     }
   }
 }
```

上面例子中，avg_price的计算结果是基于query的查询结果的，而all_avg_price的聚合是基于all data的

## 10 聚合排序

### 10.1 排序规则：

order_type：_count（数量） _key（聚合结果的key值） _term（废弃但是仍然可用，使用_key代替）,

注意，这里的排序和query的不同，这里只的是聚合的结果排序而非元数据，注意order和size的位置

```
 GET product/_search
 {
   "aggs": {
     "type_agg": {
       "terms": {
         "field": "tags",
         "order": {
           "<order_type>": "desc"
         },
         "size": 10
       }
     }
   }
 }
```

### 10.2 多级排序

即排序的优先级，按照外层优先的顺序

```
 GET product/_search?size=0
 {
   "aggs": {
     "first_sort": {
       ...
       "aggs": {
         "second_sort": {
           ...
         }
       }
     }
   }
 }
```

**上例中，先按照first_sort排序，再按照second_sort排序**

### 10.3 多层排序

即按照多层聚合中的里层某个聚合的结果进行排序 ☆

考试通常不会在某一个知识点上出现过于复杂的脚本，考试侧重于一个题目考察多个知识点，复杂的查询根据自身情况扩展性学习。

```
 GET product/_search
 {
   "size": 0,
   "aggs": {
     "tag_avg_price": {
       "terms": {
         "field": "type.keyword",
         "order": {
           "agg_stats>my_stats.sum": "desc"
         }
       },
       "aggs": {
         "agg_stats": {
          ...
           "aggs": {
             "my_stats": {
               "extended_stats": {
                 ...
               }
             }
           }
         }
       }
     }
   }
 }
```

上例中，按照里层聚合“my_stats”进行排序

## 11 聚合函数  ★

### 11.1 histogram：直方图或柱状图统计 ★

histogram是较大概率会考察的聚合函数

用途：用于区间统计，如不同价格商品区间的销售情况

**语法：**

```
 GET product/_search?size=0
 {
   "aggs": {
     "<histogram_name>": {
       "histogram": {
         "field": "price", #字段名称
         "interval": 1000,#区间间隔
         "keyed": true,#返回数据的结构化类型
         "min_doc_count": <num>,#返回桶的最小文档数阈值，即文档数小于num的桶不会被输出
         "missing": 1999#空值的替换值，即如果文档对应字段的值为空，则默认输出1999（参数值）
       }
     }
   }
 }
```

### 11.2 date-histogram

基于日期的直方图，比如统计一年每个月的销售额

**语法：**

```
 GET product/_search?size=0
 {
   "aggs": {
     "my_date_histogram": {
       "date_histogram": {
         "field": "createtime",#字段需为date类型
         "<interval_type>": "month",#时间间隔的参数可选项
         "format": "yyyy-MM", #日期的格式化输出
         "extended_bounds": {#输出空桶
           "min": "2020-01",
           "max": "2020-12"
         }
       }
     }
   }
 }
```

interval_type：时间间隔的参数可选项

* ##### fixed_interval：

  注意单位需要带上具体的数值，如2d为两天。


  * ms（毫秒）需要当心当单位过小，会导致输出桶过多而导致服务崩溃。
  * s（秒）
  * m（分钟）
  * h（小时）
  * d（天）
* ##### calendar_interval


  * month
  * quarter
  * year
* ##### interval：（废弃，但是仍然可用）

# 脚本查询

### 1 概念 ☆

Scripting是Elasticsearch支持的一种专门用于复杂场景下支持自定义编程的强大的脚本功能，ES支持多种脚本语言，如painless，其语法类似于Java,也有注释、关键字、类型、变量、函数等，其就要相对于其他脚本高出几倍的性能，并且安全可靠，可以用于内联和存储脚本。

### 2 支持的语言

**考试中不限制具体使用何种脚本语言**

* **groovy**：ES 1.4.x-5.0的默认脚本语言 ☆
* **painless**：JavaEE使用java语言开发，.Net使用C#/F#语言开发，Flutter使用Dart语言开发，同样，ES 5.0+版本后的Scripting使用的语言默认就是painless，painless是一种专门用于Elasticsearch的简单,用于内联和存储脚本，是ES 5.0+的默认脚本语言，类似于Java,也有注释、关键字、类型、变量、函数等，是一种安全的脚本语言。并且是Elasticsearch的默认脚本语言。
* **其他**：
  [expression](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-expression.html)：每个文档的开销较低：表达式的作用更多，可以非常快速地执行，甚至比编写native脚本还要快，支持javascript语法的子集：单个表达式。缺点：只能访问数字，布尔值，日期和geo_point字段，存储的字段不可用
  [mustache](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html)：提供模板参数化查询

### 3 应用场景

各种复杂的应用场景，如自定义评分、自定义聚合查询等。

### 4 考点

script经常和pipeline、reindex、search template一起考

### 5 误区

**`doc['field'].value`和 `params\['\_source']['field']`的使用区别：**

理解之间的区别是很重要的，doc['field'].value和params['_source']['field']。首先，使用doc关键字，将导致该字段的条件被加载到内存（缓存），这将导致更快的执行，但更多的内存消耗。此外，doc[...]符号只允许简单类型（不能返回一个复杂类型(JSON对象或者nested类型)），只有在非分析或单个词条的基础上有意义。但是，doc如果可能，使用仍然是从文档访问值的推荐方式，因为_source每次使用时都必须加载并解析，使用_source非常缓慢。

# Pipeline

## 1 文档位置

[Elasticsearch Guide [7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » Ingest pipelines

## 2 概念

任何管道操作需要在节点配置ingest角色

## 3 processors（工作处理器）

做题之前把我画的几个Processor先在官方文档过一遍，明白其大致含义，重点 ★，其他为预测考点，最好看一下

* Append
* Foreach ★
* Lowercase ★
* Pipeline
* Remove
* Rename
* Script ★★
* Set ★
* Split ★
* Trim ★★
* Uppercase ★
* Enrich  ★★★

# Update_by_query

## 1 文档位置

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Document APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/docs.html) » [Update By Query API](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/docs-update-by-query.html)

## 2 语法

```
POST /<target>/_update_by_query
```

# Enrich processor

## 1 文档位置

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Ingest pipelines](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ingest.html) » [Enrich your data](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ingest-enriching-data.html)

## 2 使用步骤：

### 2.1 添加 enrich data：

**添加 document （enrich data）到一个或者多个的 source index 中，这些 document 中应包含之后要添加到 incoming documents 中的数据。**

### 2.2 创建 enrich policy：

**enrich policy 中应至少包含如下参数：**
**指定source index的。**
**指定 incoming documents 和 source index 用于匹配的属性。**
**指定要添加到 incoming documents 中的属性。**

### 2.3 执行 enrich policy：

**执行完后会自动创建相应的 enrich index， enrich index 和普通索引不同，进行了优化。**

### 2.4 在 ingest pipeline 使用 enrich processor：

**enrich processor 使用 enrich index 来查询。**

# 分片分配感知 （Shard allocation awareness）

## 1 自定义属性

```
node.attr.{attribute}:{value}
```

## 2 重要的配置

### 2.1 文档位置

* **Index modules > Index Shard Allocation > **[Index-level shard allocation filtering](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/shard-allocation-filtering.html)
* **Set up Elasticsearch > **[Configuration Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/settings.html) > [Cluster-level shard allocation and routing settings](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html#shard-allocation-awareness)

### 2.2 索引级配置

```
//索引创建之前执行
PUT <index_name>
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.routing.allocation.include.{attribute}": "{value}"
  }
}
//迁移分片，索引创建之后执行
PUT test/_settings
{
  "index.routing.allocation.require.{attribute}": "{value}"
}
index.routing.allocation.include.{attribute} 　　//表示索引可以分配在包含多个值中其中一个的节点上。
index.routing.allocation.require.{attribute}　　 //表示索引要分配在包含索引指定值的节点上（通常一般设置一个值）。
index.routing.allocation.exclude.{attribute}　　 //表示索引只能分配在不包含所有指定值的节点上。
```

### 2.3 集群级配置

* **persistent：**永久性修改，persistent相关的修改保存在了/"path.data"/"cluster.name"/nodes/0/_state/global-n.st，如果想删除设置，删除此文件即可。
* **transient：**集群重启后失效，备考的时候推荐使用。

```
集群设置的优先级顺序为:
transient cluster settings // 集群重启后失效
persistent cluster settings //永久生效
settings in theelasticsearch.yml configuration file. //你懂的

PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": {attribute}
  }
}
```

## 3 Shard allocation awareness

```
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": {attribute}
  }
}
```

## 4 Forced awareness

**强制感知策略是避免意外断电导致服务器过载**

```
cluster.routing.allocation.awareness.attributes: {attribute}
cluster.routing.allocation.awareness.force.{attribute}.values: {value1,value2}
```

# 冷热集群部署

## 1 通过自定义属性标记当前节点

```
node.attr.hot_warm_cold: hot/warm/cold #名称可以自定义
```

## 2 告诉集群，你要通过哪个自定义属性来制定allocation.awareness的规则

```
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": "hot_warm_cold"
  }
}
```

## 3 新建的索引，写入hot节点

```
#指定索引名字的时候
PUT <index_name>
{
  "settings": {
    "number_of_replicas": 0,
    "index.routing.allocation.require.hot_warm_cold": "hot"
  }
}

```

## 4 迁移数据，将数据写入warm节点

```
PUT index_test/_settings
{
  "index.routing.allocation.include.hot_warm_cold": "warm"
}
```

# 跨集群搜索

**文档位置**：[Elasticsearch Guide [7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Search your data](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/search-your-data.html) » Search across clusters

### 1 准备多集群环境

**启动多个集群，考试时不需要为此专门启动集群，使用的集群就是之前题目已经启动好的集群。**

```
# 内存预算不足，可以使用下面方式在单机启动多个单节点集群
./elasticsearch -Ecluster.name=c1 -Enode.name=c1_node -Enetwork.host=192.168.3.184 -Epath.data=c1_data -Epath.logs=c1_logs -Ediscovery.type=single-node -Ehttp.port=9211 -Etransport.port=9311

./elasticsearch -Ecluster.name=c2 -Enode.name=c2_node -Enetwork.host=192.168.3.184 -Epath.data=c2_data -Epath.logs=c2_logs -Ediscovery.type=single-node -Ehttp.port=9212 -Etransport.port=9312

./elasticsearch -Ecluster.name=c3 -Enode.name=c3_node -Enetwork.host=192.168.3.184 -Epath.data=c3_data -Epath.logs=c3_logs -Ediscovery.type=single-node -Ehttp.port=9213 -Etransport.port=9313
```

### 2 配置远程集群

```
PUT _cluster/settings
{
  "persistent": {
    "cluster": {
      "remote": {
        "cluster_one": {
          "seeds": [
            "127.0.0.1:9300"
          ]
        },
        "cluster_two": {
          "seeds": [
            "127.0.0.1:9301"
          ]
        },
        "cluster_three": {
          "seeds": [
            "127.0.0.1:9302"
          ]
        }
      }
    }
  }
}
```

##### curl命令方式执行

```
集群1
curl -XPUT "http://192.168.3.184:9211/_cluster/settings" -H 'Content-Type: application/json' -d'
{"transient":{"cluster":{"remote":{"c1":{"seeds":["192.168.3.184:9311"],"transport.ping_schedule":"30s"},"c2":{"seeds":["192.168.3.184:9312"],"transport.compress":true,"skip_unavailable":true},"c3":{"seeds":["192.168.3.184:9313"]}}}}}'

集群2
curl -XPUT "http://192.168.3.184:9212/_cluster/settings" -H 'Content-Type: application/json' -d'
{"transient":{"cluster":{"remote":{"c1":{"seeds":["192.168.3.184:9311"],"transport.ping_schedule":"30s"},"c2":{"seeds":["192.168.3.184:9312"],"transport.compress":true,"skip_unavailable":true},"c3":{"seeds":["192.168.3.184:9313"]}}}}}'

集群3
curl -XPUT "http://192.168.3.184:9213/_cluster/settings" -H 'Content-Type: application/json' -d'
{"transient":{"cluster":{"remote":{"c1":{"seeds":["192.168.3.184:9311"],"transport.ping_schedule":"30s"},"c2":{"seeds":["192.168.3.184:9312"],"transport.compress":true,"skip_unavailable":true},"c3":{"seeds":["192.168.3.184:9313"]}}}}}'
```

### 3 写入测试数据。

**考试环境无需自己写入数据，如果你发现索引不存在，检查自己的代码**

```
curl -XPOST "http://192.168.3.184:9211/users/_doc" -H 'Content-Type: application/json' -d'
{"name":"user1","age":10}'

curl -XPOST "http://192.168.3.184:9212/users/_doc" -H 'Content-Type: application/json' -d'
{"name":"user2","age":20}'

curl -XPOST "http://192.168.3.184:9213/users/_doc" -H 'Content-Type: application/json' -d'
{"name":"user3","age":30}'
```

### 4 验证跨集群搜索

```
GET /users,cluster1:users,cluster2:users/_search
```

# 快照

**可搜索快照为付费功能，新用户有30天免费**

## 1 文档地址：

ILM > Index lifecycle actions > [Searchable snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-searchable-snapshot.html)

## 2 允许的阶段：

* hot
* cold
* warm
* frozen

## 3 快照&可搜索快照

### 3.1 基于普通snapshot的备份还原 ★

1. **配置文件中添加配置项：**

   ```
   path.repo: ["/usr/local/es/backup"]
   ```

   **备考环境需保证启动服务的系统账号要对以上目录有读写权限，真实考试环境，无需考虑权限问题，题目要求的目录一定是有权限的。**
2. **注册快照存储库**
3. **确保当前目录存在**
4. **确保当前账号有目录权限**

   ```
   PUT /_snapshot/my_backup
   {
   "type": "fs",
      "settings": {
        "location": "/usr/local/es/backup"
      }
    }
   ```
5. **创建快照**
6. **还原**

### 3.2 可搜索快照

* **添加**
* **注册快照存储库**
* **创建快照**
* **挂载快照**
* **还原**

# 索引别名（aliases）

## 1 文档地址：

* ##### [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) > [Index APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices.html) > [Aliases](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-aliases.html)
* ##### [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) > [Index APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices.html) > [Create Index](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-create-index.html)

## 2 别名作用：

* **保护索引：索引相对于调用者是隐藏的。**
* **别名可以结合如** `reindex`,`update_by_query`,`rollover_index`,`ILM`等完成一系列对索引的切换操作。

## 3 使用及注意事项

### 3.1 语法

```
POST /_aliases
```

### 3.2 注意事项：

* **一个索引可以绑定多个别名，一个别名也可以绑定多个索引**
* **别名不能和索引名相同**

# 滚动索引：

## 1 文档

rollover index **	** REST APIs > Index APIs > [Rollover](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-rollover-index.html)

index template    [Index Template](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-templates.html)

# 索引的生命周期 ★

## 1 文档位置

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [ILM：Manage the index lifecucle](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management.html)

**注意：ILM为7.13版本新增考点**

## 2 生命周期阶段（最多五个阶段）

**★标记为押题考点，其他考点，其他内容不代表一定不考**

### 2.1 hot

* [Set Priority](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-set-priority.html)
* [Unfollow](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-unfollow.html)
* **[Rollover](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-rollover.html)** ★
* [Read-Only](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-readonly.html)
* [Shrink](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-shrink.html)
* [Force Merge](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-forcemerge.html)
* [Searchable Snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-searchable-snapshot.html) ★

### 2.2 warm

* [Set Priority](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-set-priority.html)
* [Unfollow](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-unfollow.html)
* [Read-Only](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-readonly.html)
* [Allocate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-allocate.html)
* [Migrate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-migrate.html)
* [Shrink](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-shrink.html)
* [Force Merge](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-forcemerge.html)

### 2.3 cold

* [Set Priority](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-set-priority.html)
* [Unfollow](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-unfollow.html)
* [Read-Only](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-readonly.html)
* [Searchable Snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-searchable-snapshot.html) ★
* [Allocate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-allocate.html) ★
* [Migrate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-migrate.html)
* [Freeze](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-freeze.html) ★

4. **frozen**

* [Searchable Snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-searchable-snapshot.html)

5. **delete**

* [Wait For Snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-wait-for-snapshot.html)
* [Delete](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-delete.html) ★

## 3 生命周期过程中对索引的操作

* **[Allocate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-allocate.html)**：不同类型的节点间的分片迁移，并减少副本数量
* **[Delete](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-delete.html)**：永久删除索引
* **[Force merge](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-forcemerge.html)**：强制合并segment文件，并且物理删除已经被标记为删除的文档，此时索引只读。
* **[Freeze](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-freeze.html)**：冻结索引，释放内存空间
* **[Migrate](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-migrate.html)**：将索引分片移动到与当前 ILM 阶段对应的[数据层](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/data-tiers.html)。
* **[Read only](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-readonly.html)**：对索引设置为只读
* **[Rollover](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-rollover.html)**：通过满足"索引大小、文档数量、索引年龄"三个条件之一来创建新索引.
* **[Searchable snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-searchable-snapshot.html)**：将跟随者索引转换为常规索引。在翻转、缩小或可搜索快照操作之前自动执行。
* **[Set priority](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-set-priority.html)**：将跟随者索引转换为常规索引。在翻转、缩小或可搜索快照操作之前自动执行。
* **[Shrink](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-shrink.html)**：压缩索引，减小其主分片的数量。
* **[Unfollow](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-unfollow.html)**：将跟随者索引转换为常规索引。在翻转、缩小或可搜索快照操作之前自动执行。
* **[Wait for snapshot](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-wait-for-snapshot.html)**：将跟随者索引转换为常规索引。在翻转、缩小或可搜索快照操作之前自动执行。

## 4 使用索引模板应用ILM策略

### 4.1 文档位置：

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Index lifecycle management APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management-api.html) » Create or update lifecycle policy API

### 4.2 操作步骤

1. **配置ILM策略（可通过kibana操作）**

   ```
       PUT _ilm/policy/test_ilm
   {
     "policy": {
       "phases": {
         "hot": {
           "min_age": "0ms",
           "actions": {
             "rollover": {
               "max_primary_shard_size": "50mb",
               "max_age": "30m",
               "max_docs": 2
             },
             "set_priority": {
               "priority": 100
             }
           }
         },
         "warm": {
           "min_age": "5s",
           "actions": {
             "set_priority": {
               "priority": 50
             },
             "allocate": {
               "require": {
                 "hot_warm_cold": "warm"
               }
             }
           }
         },
         "cold": {
           "min_age": "15s",
           "actions": {
             "set_priority": {
               "priority": 0
             },
             "allocate": {
               "require": {
                 "hot_warm_cold": "cold"
               }
             }
           }
         },
         "delete": {
           "min_age": "20s",
           "actions": {
             "delete": {
               "delete_searchable_snapshot": true
             }
           }
         }
       }
     }
   }
   ```
2. ##### 创建索引模板 引用IML


   ```
   PUT _index_template/my_template
   {
     "index_patterns": ["test_ilm_index-*"], 
     "template": {
       "settings": {
         "number_of_shards": 1,
         "number_of_replicas": 0,
         "index.lifecycle.name": "test_ilm", 
         "index.lifecycle.rollover_alias": "test-alias",
         "index.routing.allocation.require.hot_warm_cold": "hot"
       }
     }
   }
   ```
3. ##### 创建索引使用索引模板


   ```
   PUT test_ilm_index-000001
   {
     "aliases": {
       "test-alias":{
         "is_write_index": true 
       }
     }
   }
   ```
4. ##### 写入数据测试


   ```
   PUT test-alias/_bulk
   {"index":{"_id":1}}
   {"title":"test data 1"}
   {"index":{"_id":2}}
   {"title":"test data 2"}
   ```
5. ##### 刷新索引方便看结果（非必要代码）


   ```
   POST test-alias/_refresh
   ```

# 数据流：Data Stream

## 1 文档位置：

Data stream > [Set up a stream](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/set-up-a-data-stream.html#secure-data-stream)

不要过多的去深究其原理，使用场景等问题，当然了解更好，但是如果需要花费大量时间去了解，那么就要权衡值不值得，因为当前的目的是认证证书，建议是仅学习其必要的知识点，也就是影响你考试的内容。如果确实是有时间，想了解，关注我的理论课和文章，保证透彻讲解。下面内容，完全针对考试，最小化学习内容。

## 2 操作步骤

### 2.1 创建ILM策略

**这是数据流所必须的**

```
PUT _ilm/policy/test_ilm
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_primary_shard_size": "50mb",
            "max_age": "30m",
            "max_docs": 2
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "5s",
        "actions": {
          "set_priority": {
            "priority": 50
          },
          "allocate": {
            "require": {
              "hot_warm_cold": "warm"
            }
          }
        }
      },
      "cold": {
        "min_age": "15s",
        "actions": {
          "set_priority": {
            "priority": 0
          },
          "allocate": {
            "require": {
              "hot_warm_cold": "cold"
            }
          }
        }
      },
      "delete": {
        "min_age": "20s",
        "actions": {
          "delete": {
            "delete_searchable_snapshot": true
          }
        }
      }
    }
  }
}
```

### 2 创建组件模板

组件模板相当于是索引模板更小粒度的拆分，使得索引模板的使用更加灵活。

```
PUT _component_template/my-mappings
{
  "template": {
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date",
          "format": "date_optional_time||epoch_millis"
        },
        "message": {
          "type": "wildcard"
        }
      }
    }
  }
}
PUT _component_template/my-settings
{
  "template": {
    "settings": {
      "index.lifecycle.name": "test_ilm",
      "number_of_replicas": 0
    }
  }
}
```

### 2.3 创建索引模板

**目的是关联哪些索引会使用到数据流**

```
PUT _index_template/my-index-template
{
  "index_patterns": ["my-data-stream*"],
  "data_stream": { },
  "composed_of": [ "my-mappings", "my-settings" ],
  "priority": 500
}
```

### 2.4 创建数据流

**数据流是针对于已存在的索引创建的，也是通过索引名称去关联索引模板中定义好的数据流的。**

```
# DELETE _data_stream/my-data-stream
# PUT _data_stream/my-data-stream
# GET _cat/shards/my-data-stream?v
# GET _data_stream/my-data-stream
# GET .ds-my-data-stream-2021.08.24-000005/_settings
# DELETE .ds-my-data-stream-2021.08.24-000005
#创建数据流
DELETE .ds-my-data-stream-2021.08.24-000006
```

# 集群安全：Security

## 1 文档位置：

##### [Elasticsearch Guide [7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Secure the Elastic Stack](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/secure-cluster.html) » [Configure security for the Elastic Stack](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/configuring-stack-security.html) » Set up minimal security for Elasticsearch

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [Secure the Elastic Stack](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/secure-cluster.html) » [Configure security for the Elastic Stack](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/configuring-stack-security.html) » Set up basic security for the Elastic Stack

## 2 多节点Sucurity步骤

#### 2.1 第一步：配置文件 elasticsearch.yml

##### 启用 security安全认证

```
#开启security
xpack.security.enabled: true
#配置SSL证书
xpack.security.transport.ssl.enabled: true
```

##### 设置验证模式为：certificate

```
xpack.security.transport.ssl.verification_mode: certificate 
```

##### 设置证书路径

```
xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12 
xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
```

#### 2.2 第二步：给节点颁发证书，生成：elastic-stack-ca.p12 文件。

```
bin/elasticsearch-certutil ca
```

#### 2. 3 第三步：为节点颁发证书，生成： elastic-certificates.p12 证书

```
bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12
```

#### 2.4 第四步：把证书拷贝的每个节点（如果设置了certs/目录，此目录在config目录下），按照提示操作

```
scp elastic-certificates.p12 root@192.168.3.182:/usr/local/elasticsearch-7.13.0
```

#### 2.5 第五步：启动所有节点（练习的时候记得清空data中的节点数据，考试不能）

#### 2.6 第六步：设置集群密码

```
bin/elasticsearch-setup-passwords interactive
```

#### 2.7 第七步 ：配置Kibana（考试的时候不用配置，因为官方提前已经给你配置了）

## 3 单节点Security步骤2.3.1 第一步：开启Security安全功能

```
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
```

#### 3.2 第二步 ：重启节点服务（在备考时，启动之前删除data目录，考试时不要删）

#### 3.3 第三步：

```
 #交互式设置密码
 ./elasticsearch-setup-passwords interactive
```

# RBAC ★

**注意：考试时可以基于Kibana操作，但是备考时要保证基于Kibana和基于DSL的方式都会做。下面为基于DSL的实现方式。**

## 1 文档位置

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Security APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-api.html) » [Create or update users API](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-api-put-user.html)

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Security APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-api.html) » Create or update roles API

## 2 创建角色

例如：配置一个名为 role_master 的角色，创建用户 `jian`密码 `password`, 邮件 `elastic.org.cn`, 并绑定当前角色，要求

* 该角色在集群上有“monitor”权限，
* 该角色对' index1，index2 '索引具有只读权限，
* 该角色只能看到title字段包含“msb”的文档
* 角色只能看到'title，body '字段

**文档地址**：X-Pack APIs > Security APIs >

```
POST /_security/role/role_master
{
  "cluster": ["all"], 
  "indices": [
    {
      "names": [ "index1", "index2" ],
      "privileges": ["read"], //只读权限 考试中可能会出现的情况 read write all
      "field_security" : { //可选 字段权限
        "grant" : [ "title", "body" ]
      },
      "query": "{\"match\": {\"title\": \"msb\"}}" //可选
    }
  ],
  "run_as": [ "other_user" ], // optional
}
```

## 3 创建用户

**文档地址：**X-Pack APIs > Security APIs > [Create or update users](https://www.elastic.co/guide/en/elasticsearch/reference/7.2/security-api-put-user.html)

```
POST /_security/user/jian
{
  "password" : "password",
  "roles" : [ "role_master", "kibana_user" ],
  "full_name" : "elastic开源社区",
  "email" : "elastic.org.cn"
}
```

# 跨集群复制

## 1 概念 ☆：

跨集群复制 (CCR) 功能支持将特定索引从一个 ElasticSearch 集群复制到一个或多个 ElasticSearch 集群。除了跨数据中心复制之外，CCR 还有许多其他用例，包括数据本地化（将数据复制到距离用户/应用程序服务器更近的位置，例如，将产品目录复制到全球 20 个不同的数据中心），或者将数据从 Elasticsearch 集群复制到中央报告集群（例如，全球 1000 家银行分行都向其本地 Elasticsearch 集群写入数据，并复制回总部的集群用于报告）。

## 2 跨集群复制好处

* 如果主群集发生故障，则进行灾难恢复。辅助群集可以用作热备份。不可抗力，比如火山、地震、台风等，机房直接GG
* 实现就近访问，因此可以在本地提供订阅服务			总公司-分公司。
* 多集群集中治理。
* 一个部门维护多个集群，多个集群订阅到本地，可视化分析报告。比如多个分公司都有自己的数据，如华为-荣耀，要集中起来做数据报表。

## 3 前置条件：

* 需要远程集群
* 新集群版本必须高于旧集群，并且需要满足兼容性条件（附件）
* 需要白金级会员以上权限或者开启30天试用。详情：[戳我](https://www.elastic.co/cn/subscriptions)
* **远程需要节点 **`remote_cluster_client`角色，详情：[戳我](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/modules-node.html#node-roles)
* 如果集群开启了Security，那么远程集群需要和本地集群使用相同的证书

# 异步搜索

## 1 文档位置：

**[Elasticsearch Guide **[7.13]](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index.html) » [REST APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/rest-apis.html) » [Search APIs](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/search.html) » [Async search](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/async-search.html)

## 2 使用

### 2.1 提交异步搜索

```
POST /sales*/_async_search?size=0
{
  "sort": [
    { "date": { "order": "asc" } }
  ],
  "aggs": {
    "sale_date": {
      "date_histogram": {
        "field": "date",
        "calendar_interval": "1d"
      }
    }
  }
}
```

### 2.2 响应结果

```
{
  "id" : "FmRldE8zREVEUzA2ZVpUeGs2ejJFUFEaMkZ5QTVrSTZSaVN3WlNFVmtlWHJsdzoxMDc=", 
  "is_partial" : true, 
  "is_running" : true, 
  "start_time_in_millis" : 1583945890986,
  "expiration_time_in_millis" : 1584377890986,
  "response" : {
    "took" : 1122,
    "timed_out" : false,
    "num_reduce_phases" : 0,
    "_shards" : {
      "total" : 562, 
      "successful" : 3, 
      "skipped" : 0,
      "failed" : 0
    },
    "hits" : {
      "total" : {
        "value" : 157483, 
        "relation" : "gte"
      },
      "max_score" : null,
      "hits" : [ ]
    }
  }
}
```

### 2.3 参数释义

* id：可用于监控其进度、检索其结果和/或删除它的异步搜索的标识符
* is_partial：当查询不再运行时，指示是否已在所有分片上成功完成搜索失败。在执行查询时，is_partial始终设置为true
* is_running：搜索是否仍在执行中或已完成
* total：总体而言，将在多少个分片上执行搜索
* successful：有多少分片已成功完成搜索
* value：当前匹配查询的文档有多少，属于已经完成搜索的分片

### 2.4 查看异步搜索

```
GET /_async_search/FmRldE8zREVEUzA2ZVpUeGs2ejJFUFEaMkZ5QTVrSTZSaVN3WlNFVmtlWHJsdzoxMDc=
```

### 2.5 查看异步搜索状态

```
GET /_async_search/status/FmRldE8zREVEUzA2ZVpUeGs2ejJFUFEaMkZ5QTVrSTZSaVN3WlNFVmtlWHJsdzoxMDc=
```

### 2.6 删除异步搜索

```
DELETE /_async_search/FmRldE8zREVEUzA2ZVpUeGs2ejJFUFEaMkZ5QTVrSTZSaVN3WlNFVmtlWHJsdzoxMDc=
```

# 可视化上传：Kibana Data Visualizer

Kibana：Machine Learning > Data Visualizer > Import data
